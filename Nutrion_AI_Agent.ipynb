{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SutapaSusovita/Nutrition_Agent/blob/main/Nutrion_AI_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wGB8Ds0GtdsZ"
      },
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Agents Lab Notebook v1.0.0\n",
        "This notebook contains steps and code to demonstrate the use of agents\n",
        "configured in Agent Lab in watsonx.ai. It introduces Python API commands\n",
        "for authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n",
        "\n",
        "**Note:** Notebook code generated using Agent Lab will execute successfully.\n",
        "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
        "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "## Notebook goals\n",
        "The learning goals of this notebook are:\n",
        "\n",
        "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
        "* Creating an agent with a set of tools using a specified model and parameters\n",
        "* Invoking the agent to generate a response\n",
        "\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ibm-watsonx-ai langchain-ibm langgraph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4ecCP-4uHiC",
        "outputId": "4d10e749-b5cb-4f53-9cbd-4d44b6d9b40d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ibm-watsonx-ai\n",
            "  Downloading ibm_watsonx_ai-1.3.32-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting langchain-ibm\n",
            "  Downloading langchain_ibm-0.3.15-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.32.3)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.5.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2025.8.3)\n",
            "Collecting lomond (from ibm-watsonx-ai)\n",
            "  Downloading lomond-0.3.3-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (25.0)\n",
            "Collecting ibm-cos-sdk<2.15.0,>=2.12.0 (from ibm-watsonx-ai)\n",
            "  Downloading ibm_cos_sdk-2.14.3.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (5.5.2)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.39 in /usr/local/lib/python3.11/dist-packages (from langchain-ibm) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm-watsonx-ai) (0.16.0)\n",
            "Collecting ibm-cos-sdk-core==2.14.3 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai)\n",
            "  Downloading ibm_cos_sdk_core-2.14.3.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-s3transfer==2.14.3 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai)\n",
            "  Downloading ibm_cos_sdk_s3transfer-2.14.3.tar.gz (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<=1.0.1,>=0.10.0 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.9.0.post0)\n",
            "Collecting requests (from ibm-watsonx-ai)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (0.4.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (4.14.1)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ibm-watsonx-ai) (3.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from lomond->ibm-watsonx-ai) (1.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (1.3.1)\n",
            "Downloading ibm_watsonx_ai-1.3.32-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_ibm-0.3.15-py3-none-any.whl (32 kB)\n",
            "Downloading langgraph-0.6.4-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.14.3-py3-none-any.whl size=77232 sha256=a029a20792e87c7f8d601220d441d5192833ee53d7f222632c7262ba60feb6c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/fa/85/9a1004ed234750540a7a90f34000bc1208e723f3613eaafc2b\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.14.3-py3-none-any.whl size=662101 sha256=858743d3e1ab014e3c11eb5575ea6972d5d5a4895349401f3e6b659407341702\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/25/ac/fa87dd4aeda7eba0f3e7e891c52f9c92c8b2ea49963119d9df\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.14.3-py3-none-any.whl size=90203 sha256=183316515fc448a5f94299bc038ea04ecc68419d673afa1493685c953277ec11\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/03/6f/e85bbf1471a809e7892239f69458cef2cd69ee38fb543339c8\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: requests, ormsgpack, lomond, jmespath, ibm-cos-sdk-core, langgraph-sdk, ibm-cos-sdk-s3transfer, ibm-cos-sdk, langgraph-checkpoint, ibm-watsonx-ai, langgraph-prebuilt, langchain-ibm, langgraph\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 ibm-watsonx-ai-1.3.32 jmespath-1.0.1 langchain-ibm-0.3.15 langgraph-0.6.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 lomond-0.3.3 ormsgpack-1.10.0 requests-2.32.4\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_Bddc_gztdsc"
      },
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from langchain_ibm import ChatWatsonx\n",
        "from ibm_watsonx_ai import APIClient\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
        "import json\n",
        "import requests"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltjqY2-wtdsd"
      },
      "cell_type": "markdown",
      "source": [
        "## watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
        "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
      ]
    },
    {
      "metadata": {
        "id": "fdWqY0oItdse"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PoeJOMLVtdse"
      },
      "cell_type": "markdown",
      "source": [
        "# Using the agent\n",
        "These cells demonstrate how to create and invoke the agent\n",
        "with the selected models, tools, and parameters.\n",
        "\n",
        "## Defining the model id\n",
        "We need to specify model id that will be used for inferencing:"
      ]
    },
    {
      "metadata": {
        "id": "x0dwh-N9tdse"
      },
      "cell_type": "code",
      "source": [
        "model_id = \"ibm/granite-3-3-8b-instruct\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uLf3h_F1tdsf"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the\n",
        "result:"
      ]
    },
    {
      "metadata": {
        "id": "LJQStVOatdsf"
      },
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"max_tokens\": 2000,\n",
        "    \"presence_penalty\": 0,\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hgR88KWYtdsf"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining the project id or space id\n",
        "The API requires project id or space id that provides the context for the call. We will obtain\n",
        "the id from the project or space in which this notebook runs:"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEpbVVORtdsf",
        "outputId": "2f637632-b18d-4e2d-d05a-2f8b7064c614"
      },
      "cell_type": "code",
      "source": [
        "# ✅ Directly set your project_id here\n",
        "project_id = \"46f752f6-63af-49e3-a01c-b579cde1e0e1\"\n",
        "space_id = os.getenv(\"SPACE_ID\")\n",
        "\n",
        "def get_credentials():\n",
        "    return {\n",
        "        \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
        "        \"apikey\": getpass.getpass(\"Please enter your api key (hit enter): \")\n",
        "    }\n",
        "\n",
        "def get_bearer_token():\n",
        "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
        "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n",
        "    response = requests.post(url, headers=headers, data=data)\n",
        "    return response.json().get(\"access_token\")\n",
        "\n",
        "credentials = get_credentials()\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your api key (hit enter): ··········\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Z7ngkfyztdsg"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the agent\n",
        "We need to create the agent using the properties we defined so far:"
      ]
    },
    {
      "metadata": {
        "id": "iJDrC8zCtdsg"
      },
      "cell_type": "code",
      "source": [
        "# ✅ Pass project_id explicitly to APIClient\n",
        "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n",
        "\n",
        "# Create the chat model\n",
        "def create_chat_model():\n",
        "    chat_model = ChatWatsonx(\n",
        "        model_id=model_id,\n",
        "        url=credentials[\"url\"],\n",
        "        space_id=space_id,\n",
        "        project_id=project_id,\n",
        "        params=parameters,\n",
        "        watsonx_client=client,\n",
        "    )\n",
        "    return chat_model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_l_7Qj3tdsg"
      },
      "cell_type": "code",
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "\n",
        "\n",
        "vector_index_id = \"76e119fd-5004-430c-a3ee-8d17270ca3d1\"\n",
        "\n",
        "def create_rag_tool(vector_index_id, api_client):\n",
        "    config = {\n",
        "        \"vectorIndexId\": vector_index_id,\n",
        "        \"projectId\": project_id\n",
        "    }\n",
        "\n",
        "    tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about Farming\"\n",
        "\n",
        "    return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n",
        "\n",
        "\n",
        "\n",
        "def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
        "    from langchain_core.tools import StructuredTool\n",
        "    utility_agent_tool = Toolkit(\n",
        "        api_client=api_client\n",
        "    ).get_tool(tool_name)\n",
        "\n",
        "    tool_description = utility_agent_tool.get(\"description\")\n",
        "\n",
        "    if (kwargs.get(\"tool_description\")):\n",
        "        tool_description = kwargs.get(\"tool_description\")\n",
        "    elif (utility_agent_tool.get(\"agent_description\")):\n",
        "        tool_description = utility_agent_tool.get(\"agent_description\")\n",
        "\n",
        "    tool_schema = utility_agent_tool.get(\"input_schema\")\n",
        "    if (tool_schema == None):\n",
        "        tool_schema = {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "            \"properties\": {\n",
        "                \"input\": {\n",
        "                    \"description\": \"input for the tool\",\n",
        "                    \"type\": \"string\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def run_tool(**tool_input):\n",
        "        query = tool_input\n",
        "        if (utility_agent_tool.get(\"input_schema\") == None):\n",
        "            query = tool_input.get(\"input\")\n",
        "\n",
        "        results = utility_agent_tool.run(\n",
        "            input=query,\n",
        "            config=params\n",
        "        )\n",
        "\n",
        "        return results.get(\"output\")\n",
        "\n",
        "    return StructuredTool(\n",
        "        name=tool_name,\n",
        "        description = tool_description,\n",
        "        func=run_tool,\n",
        "        args_schema=tool_schema\n",
        "    )\n",
        "\n",
        "\n",
        "def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
        "    from langchain_core.tools import StructuredTool\n",
        "    import ast\n",
        "\n",
        "    def call_tool(**kwargs):\n",
        "        tree = ast.parse(tool_code, mode=\"exec\")\n",
        "        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
        "        function_name = custom_tool_functions[0].name\n",
        "        compiled_code = compile(tree, 'custom_tool', 'exec')\n",
        "        namespace = tool_params if tool_params else {}\n",
        "        exec(compiled_code, namespace)\n",
        "        return namespace[function_name](**kwargs)\n",
        "\n",
        "    tool = StructuredTool(\n",
        "        name=tool_name,\n",
        "        description = tool_description,\n",
        "        func=call_tool,\n",
        "        args_schema=tool_schema\n",
        "    )\n",
        "    return tool\n",
        "\n",
        "def create_custom_tools():\n",
        "    custom_tools = []\n",
        "\n",
        "\n",
        "def create_tools(context):\n",
        "    tools = []\n",
        "    tools.append(create_rag_tool(vector_index_id, client))\n",
        "\n",
        "    config = {\n",
        "        \"maxResults\": 10\n",
        "    }\n",
        "    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n",
        "    config = {\n",
        "    }\n",
        "    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n",
        "    config = {\n",
        "        \"maxResults\": 5\n",
        "    }\n",
        "    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n",
        "    config = {\n",
        "    }\n",
        "    tools.append(create_utility_agent_tool(\"Weather\", config, client))\n",
        "\n",
        "    return tools"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "def create_agent(context):\n",
        "    chat_model = create_chat_model()\n",
        "    tools = create_tools(context)\n",
        "    memory = MemorySaver()\n",
        "\n",
        "    instructions = \"\"\"You are a helpful nutrition AI agent.\n",
        "Ask the user for their age, gender, weight, height, dietary preferences (e.g., vegetarian, keto), allergies, medical conditions (e.g., diabetes, PCOS), cultural preferences, and fitness goals (e.g., weight loss, muscle gain). Store the responses securely and use them to personalize future suggestions.\n",
        "Generate a daily or weekly meal plan that aligns with the user's profile: dietary preferences, medical conditions, and fitness goals. Ensure nutritional balance (macros + micronutrients) and cultural relevance. Include breakfast, lunch, dinner, and optional snacks with calorie counts and prep details.\n",
        "When a user inputs a food they dislike, are allergic to, or want a healthier version of, suggest smart alternatives. For example, if a user inputs \"white rice\", you might suggest \"quinoa\" or \"cauliflower rice\" and explain why the alternative is healthier.\n",
        "Whenever a recommendation is made, provide a short, clear explanation such as:\n",
        "- \"This food is high in fiber, which supports digestion.\"\n",
        "- \"This alternative has a lower glycemic index, which is better for diabetes.\" Offer contextual, science-backed reasons to help the user make informed decisions.\n",
        "If a user uploads a food photo or grocery label, extract the food item name using image recognition. Cross-reference the item with a nutrition database to determine if it's healthy based on the user's profile. Respond with nutritional info and suggestions if needed.\n",
        "If a user says they disliked a meal, were still hungry, or experienced a symptom, adjust future recommendations accordingly. Ask follow-up questions like: \"Would you prefer a lighter/heavier meal next time?\" or \"Should I avoid this ingredient in future plans?\"\n",
        "\"\"\"\n",
        "\n",
        "    # Instead of passing 'prompt' directly to create_react_agent,\n",
        "    # embed instructions into the model itself\n",
        "    chat_model = chat_model.bind(system=instructions)\n",
        "\n",
        "    agent = create_react_agent(\n",
        "        chat_model,\n",
        "        tools=tools,\n",
        "        checkpointer=memory\n",
        "    )\n",
        "    return agent\n"
      ],
      "metadata": {
        "id": "nG0kELIG05rY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pKCH5oFrtdsh"
      },
      "cell_type": "markdown",
      "source": [
        "## Invoking the agent\n",
        "Let us now use the created agent, pair it with the input, and generate the response to your question:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage, AIMessage\n",
        "\n",
        "agent = create_agent(context)\n",
        "\n",
        "def convert_messages(messages):\n",
        "    converted_messages = []\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"user\":\n",
        "            converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
        "        elif message[\"role\"] == \"assistant\":\n",
        "            converted_messages.append(AIMessage(content=message[\"content\"]))\n",
        "    return converted_messages\n",
        "\n",
        "question = input(\"Question: \")\n",
        "\n",
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": question\n",
        "}]\n",
        "\n",
        "generated_response = agent.invoke(\n",
        "    {\"messages\": convert_messages(messages)},\n",
        "    config={\"configurable\": {\"thread_id\": \"42\"}}\n",
        ")\n",
        "\n",
        "print_full_response = False\n",
        "\n",
        "if print_full_response:\n",
        "    print(generated_response)\n",
        "else:\n",
        "    if isinstance(generated_response, dict) and \"messages\" in generated_response:\n",
        "        result = generated_response[\"messages\"][-1].content\n",
        "    else:\n",
        "        result = str(generated_response)\n",
        "    print(f\"Agent: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z7K8EnM09Y5",
        "outputId": "93b88ca6-5075-4954-b0fd-524bcd0a57e6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Hi, I want you to create a weekly vegetarian meal plan for me. I’m 28 years old, female, 60 kg, 165 cm tall. I have no allergies, but I have mild PCOS. I prefer Indian cuisine and my goal is weight loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ibm_watsonx_ai.wml_client_error:Missing required properties of the tool's input schema. The following properties are required: ['q'].\n",
            "WARNING:ibm_watsonx_ai.wml_client_error:Failure during run tool. (POST https://api.dataplatform.cloud.ibm.com/wx/v1-beta/utility_agent_tools/run)\n",
            "Status code: 500, body: DDG detected an anomaly in the request, you are likely making requests too quickly.\n",
            "WARNING:ibm_watsonx_ai.wml_client_error:Missing required properties of the tool's input schema. The following properties are required: ['q'].\n",
            "WARNING:ibm_watsonx_ai.wml_client_error:Failure during run tool. (POST https://api.dataplatform.cloud.ibm.com/wx/v1-beta/utility_agent_tools/run)\n",
            "Status code: 500, body: DDG detected an anomaly in the request, you are likely making requests too quickly.\n",
            "WARNING:ibm_watsonx_ai.wml_client_error:Missing required properties of the tool's input schema. The following properties are required: ['q'].\n",
            "WARNING:ibm_watsonx_ai.wml_client_error:Failure during run tool. (POST https://api.dataplatform.cloud.ibm.com/wx/v1-beta/utility_agent_tools/run)\n",
            "Status code: 500, body: DDG detected an anomaly in the request, you are likely making requests too quickly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent: To create a suitable meal plan for you, I'll need to consider your dietary preferences, health condition, and weight loss goals. Here's a simple weekly vegetarian meal plan focusing on Indian cuisine that could help with weight loss while managing mild PCOS. Please consult with a nutritionist or dietitian for personalized advice.\n",
            "\n",
            "**Day 1:**\n",
            "- **Breakfast:** Moong dal chilla (mung bean pancakes) with tomato chutney.\n",
            "- **Lunch:** Quinoa salad with mixed vegetables (carrots, bell peppers, cucumbers) and lemon-tahini dressing.\n",
            "- **Dinner:** Palak paneer (spinach and tofu) with whole wheat roti.\n",
            "\n",
            "**Day 2:**\n",
            "- **Breakfast:** Oats upma with peas and carrots.\n",
            "- **Lunch:** Chickpea curry (chana masala) with brown rice.\n",
            "- **Dinner:** Mixed vegetable curry with besan (chickpea flour) gravy, served with millet.\n",
            "\n",
            "**Day 3:**\n",
            "- **Breakfast:** Smoothie with spinach, banana, almond milk, and chia seeds.\n",
            "- **Lunch:** Dal tadka with whole wheat naan.\n",
            "- **Dinner:** Baingan bharta (roasted eggplant mashed with spices) with quinoa.\n",
            "\n",
            "**Day 4:**\n",
            "- **Breakfast:** Poha (flattened rice) with peanuts and vegetables.\n",
            "- **Lunch:** Rajma (kidney beans) with whole wheat chapati.\n",
            "- **Dinner:** Methi (fenugreek) theplis with dals and a side of mixed salad.\n",
            "\n",
            "**Day 5:**\n",
            "- **Breakfast:** Idli with sambar (lentil soup).\n",
            "- **Lunch:** Paneer butter masala with sautéed spinach and brown rice.\n",
            "- **Dinner:** Aloo gobi (potato and cauliflower) with whole wheat paratha.\n",
            "\n",
            "**Day 6:**\n",
            "- **Breakfast:** Dhokla (steamed savory cake made from fermented rice and chickpea flour).\n",
            "- **Lunch:** Vegetable pulao with cottage cheese (paneer) gravy.\n",
            "- **Dinner:** Chole (chickpeas) with whole wheat puri.\n",
            "\n",
            "**Day 7:**\n",
            "- **Breakfast:** Upma with mixed vegetables.\n",
            "- **Lunch:** Dal fry with mixed vegetable thali.\n",
            "- **Dinner:** Vegetable korma with whole wheat pita bread.\n",
            "\n",
            "Remember to drink plenty of water throughout the day and adjust portion sizes according to your specific calorie needs. Incorporating physical activity into your routine is also crucial for weight loss.\n",
            "\n",
            "For more personalized advice, consider consulting a registered dietitian or nutritionist who can provide guidance based on your specific health metrics and lifestyle.\n",
            "\n",
            "**Note:** This meal plan is a general guideline and does not account for individual nutritional needs or potential dietary restrictions. Always consult with a healthcare professional before making significant changes to your diet, especially when managing a health condition like PCOS.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NZA_nbZ5tdsi"
      },
      "cell_type": "markdown",
      "source": [
        "# Next steps\n",
        "You successfully completed this notebook! You learned how to use\n",
        "watsonx.ai inferencing SDK to generate response from the foundation model\n",
        "based on the provided input, model id and model parameters. Check out the\n",
        "official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n",
        "\n",
        "<a id=\"copyrights\"></a>\n",
        "### Copyrights\n",
        "\n",
        "Licensed Materials - Copyright © 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
        "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
        "\n",
        "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
        "\n",
        "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.10",
      "language": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}